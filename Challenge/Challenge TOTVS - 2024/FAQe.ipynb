{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dlURgSQk0ln7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb010a6-619a-46d9-d699-1a34d862cd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/798.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install Pydub openai-whisper openai noisereduce -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHyc0acl0pZF",
        "outputId": "d00bd8eb-1a4b-46e3-e9cb-fd7d4eaca997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IoFK7k0_0pMN"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.effects import low_pass_filter, high_pass_filter, compress_dynamic_range\n",
        "\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "\n",
        "import librosa\n",
        "\n",
        "import soundfile as sf\n",
        "\n",
        "import tempfile\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import noisereduce as nr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# montando o drive e pegando o diretorio com os áudios\n",
        "drive.mount('/content/drive')\n",
        "diretorio = '/content/drive/MyDrive/Challenge TOTVS Amostra de Dados v2/Amostra de Dados'\n",
        "\n",
        "arquivos = os.listdir(diretorio)\n",
        "\n",
        "# pegando as instruções do chat got por meio de um txt no drive, deixando o\n",
        "# código mais limpo (as instruções estão na documentação)\n",
        "with open('/content/drive/MyDrive/Challenge TOTVS Amostra de Dados v2/instrucoes.txt', 'r') as file:\n",
        "    instrucoes_gpt = file.read()\n",
        "\n",
        "# pegando a api por um txt no drive por questões de segurança\n",
        "with open('/content/drive/MyDrive/Challenge TOTVS Amostra de Dados v2/api_key.txt', 'r') as file:\n",
        "    api_key = file.read()\n",
        "\n",
        "# baixando o modelo medium do whisper para transcrição ed inicializando as listas\n",
        "model = whisper.load_model('medium')\n",
        "dfs, respostas = [], []\n",
        "\n",
        "# criando a função de processamento de áudios, que recebe o áudio do drive como parâmetro\n",
        "def processar_audio(caminho_arquivo):\n",
        "\n",
        "    # carregando os áudios e retirando o ruído\n",
        "    y, sr = librosa.load(caminho_arquivo, sr=None)\n",
        "    noise_sample = y[:int(sr)] # amostra do ruído\n",
        "    y_reduced_noise = nr.reduce_noise(y=y, sr=sr, y_noise=noise_sample, prop_decrease=0.8)\n",
        "\n",
        "    # criando um arquivo temporário para continuar os processos\n",
        "    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:\n",
        "        sf.write(temp_wav.name, y_reduced_noise, sr)\n",
        "        temp_wav_path = temp_wav.name\n",
        "\n",
        "    # carregando o arquivo temporário e passando filtros nas freqûencias do áudio para melhorá-lo\n",
        "    audio = AudioSegment.from_wav(temp_wav_path)\n",
        "    audio_low = low_pass_filter(audio, cutoff=4000)\n",
        "    audio_high = high_pass_filter(audio_low, cutoff=80)\n",
        "\n",
        "    # aumentando o volume do áudio\n",
        "    audio_amplificado = audio_high.apply_gain(7.0)\n",
        "\n",
        "    #retornando o áudio final\n",
        "    return audio_amplificado\n",
        "\n",
        "\n",
        "# definindo a função que normaliza as respostas do GPT\n",
        "def limpar_resposta(resposta):\n",
        "    resposta = re.sub(r'^[-\\*\\s]+', '', resposta, flags=re.MULTILINE).strip()\n",
        "    return re.sub(r'\\n\\s*\\n', '\\n', resposta).split('\\n')\n",
        "\n",
        "# definindo a função que transforma as respostas do GPT em dataframe\n",
        "def processar_resposta(linhas, arquivo):\n",
        "\n",
        "    # inicializando as listas que virarão colunas\n",
        "    topicos, notas, justificativas = [], [], []\n",
        "\n",
        "    # fazendo a separção das respostas por linhas, separando tópicos, notas e justificativas por : e -\n",
        "    for linha in linhas:\n",
        "        topico, detalhes = linha.split(': ', 1) #separando os tópicos\n",
        "        if ' - ' in detalhes:\n",
        "            nota, justificativa = detalhes.split(' - ', 1) #separando as notas das justificativas\n",
        "        else:\n",
        "            nota, justificativa = detalhes, ''\n",
        "        topicos.append(topico)\n",
        "        notas.append(nota)\n",
        "        justificativas.append(justificativa)\n",
        "\n",
        "    # retornando o DF utilizando as listas e também o nome do arquivo como ID\n",
        "    return pd.DataFrame({\n",
        "        'Tópico': topicos,\n",
        "        'Nota': notas,\n",
        "        'Justificativa': justificativas,\n",
        "        'ID': arquivo\n",
        "    })\n",
        "\n",
        "# utilizando um loop dentro da pasta de áudios\n",
        "for arquivo in arquivos:\n",
        "    if arquivo.endswith('.wav'):\n",
        "        caminho_arquivo = os.path.join(diretorio, arquivo)\n",
        "\n",
        "        # realizando o processamento do áudio\n",
        "        try:\n",
        "            audio_amplificado = processar_audio(caminho_arquivo)\n",
        "\n",
        "            # criando um arquivo temporário para que a transcrição seja feita\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_final_wav:\n",
        "                audio_amplificado.export(temp_final_wav.name, format='wav')\n",
        "                temp_final_wav_path = temp_final_wav.name\n",
        "\n",
        "            result = model.transcribe(temp_final_wav_path)\n",
        "\n",
        "        # desfazendo o arquivo temporário\n",
        "        finally:\n",
        "            os.unlink(temp_final_wav_path)\n",
        "\n",
        "        # criando o texto do gpt que pega as instruções junto do resultado da transcrição\n",
        "        texto_gpt = instrucoes_gpt + result['text'].replace('\\n', ' ')\n",
        "\n",
        "        # acionando a API\n",
        "        client = OpenAI(api_key=api_key)\n",
        "\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": texto_gpt}],\n",
        "            model=\"gpt-4o-2024-08-06\",\n",
        "        )\n",
        "\n",
        "        # limpando a resposta do gpt, criando o DF e adiconando na lista\n",
        "        resposta = chat_completion.choices[0].message.content\n",
        "        linhas = limpar_resposta(resposta)\n",
        "        df = processar_resposta(linhas, arquivo)\n",
        "        dfs.append(df)\n",
        "\n",
        "# concatenando todos os DFs e transformando em csv\n",
        "df_final = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Dicionário de mapeamento de números por extenso para algarismos\n",
        "numeros_extenso_para_algarismos = {\n",
        "    'Um': 1,\n",
        "    'Dois': 2,\n",
        "    'Três': 3,\n",
        "    'Quatro': 4,\n",
        "    'Cinco': 5,\n",
        "    'Seis': 6,\n",
        "    'Sete': 7,\n",
        "    'Oito': 8,\n",
        "    'Nove': 9,\n",
        "    'Dez': 10\n",
        "}\n",
        "\n",
        "# Substituindo os números por extenso pelos algarismos na coluna 'Nota'\n",
        "df_final['Nota'] = df_final['Nota'].replace(numeros_extenso_para_algarismos)\n",
        "\n",
        "# retirando os NaN's da coluna justificativa na parte de \"Notas\",\n",
        "# \"pontos adicionais(quando respondidos com 'não')\" e \"classificação do cliente\"\n",
        "df_final['Justificativa'] = df_final['Justificativa'].fillna('Sem justificativa')\n",
        "\n",
        "# transformando em csv e armazenando no Drive\n",
        "df_final.to_csv('/content/drive/MyDrive/Challenge TOTVS Amostra de Dados v2s/respostas_gpt_4.csv', index=False)"
      ],
      "metadata": {
        "id": "zHKsuHtxaPu8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}